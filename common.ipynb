{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f11451b-6711-4425-b1f4-b45f01d12369",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# class LeNet:\n",
    "# \t@staticmethod\n",
    "# \tdef build(width, height, depth, classes):\n",
    "# \t\t# initialize the model\n",
    "# \t\tmodel = Sequential()\n",
    "# \t\tinputShape = (height, width, depth)\n",
    "\n",
    "# \t\t# if we are using \"channels first\", update the input shape\n",
    "# \t\tif K.image_data_format() == \"channels_first\":\n",
    "# \t\t\tinputShape = (depth, height, width)\n",
    "\n",
    "# \t\t# first set of CONV => RELU => POOL layers\n",
    "# \t\tmodel.add(Conv2D(20, (5, 5), padding=\"same\",\n",
    "# \t\t\tinput_shape=inputShape))\n",
    "# \t\tmodel.add(Activation(\"relu\"))\n",
    "# \t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# \t\t# second set of CONV => RELU => POOL layers\n",
    "# \t\tmodel.add(Conv2D(50, (5, 5), padding=\"same\"))\n",
    "# \t\tmodel.add(Activation(\"relu\"))\n",
    "# \t\tmodel.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "# \t\t# first (and only) set of FC => RELU layers\n",
    "# \t\tmodel.add(Flatten())\n",
    "# \t\tmodel.add(Dense(500))\n",
    "# \t\tmodel.add(Activation(\"relu\"))\n",
    "\n",
    "# \t\t# softmax classifier\n",
    "# \t\tmodel.add(Dense(classes))\n",
    "# \t\t# model.add(Activation(\"softmax\"))\n",
    "\n",
    "# \t\t# return the constructed network architecture\n",
    "# \t\treturn model\n",
    "# class MiniVGGNet:\n",
    "# \t@staticmethod\n",
    "# \tdef build(width, height, depth, classes):\n",
    "# \t\t# initialize the model along with the input shape to be\n",
    "# \t\t# \"channels last\" and the channels dimension itself\n",
    "# \t\tmodel = Sequential()\n",
    "# \t\tinputShape = (height, width, depth)\n",
    "# \t\tchanDim = -1\n",
    "\n",
    "# \t\t# if we are using \"channels first\", update the input shape\n",
    "# \t\t# and channels dimension\n",
    "# \t\tif K.image_data_format() == \"channels_first\":\n",
    "# \t\t\tinputShape = (depth, height, width)\n",
    "# \t\t\tchanDim = 1\n",
    "\n",
    "# \t\t# first CONV => RELU => CONV => RELU => POOL layer set\n",
    "# \t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "# \t\t\tinput_shape=inputShape))\n",
    "# \t\tmodel.add(Activation(\"relu\"))\n",
    "# \t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "# \t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "# \t\tmodel.add(Activation(\"relu\"))\n",
    "# \t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "# \t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# \t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "# \t\t# second CONV => RELU => CONV => RELU => POOL layer set\n",
    "# \t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "# \t\tmodel.add(Activation(\"relu\"))\n",
    "# \t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "# \t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "# \t\tmodel.add(Activation(\"relu\"))\n",
    "# \t\tmodel.add(BatchNormalization(axis=chanDim))\n",
    "# \t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# \t\tmodel.add(Dropout(0.25))\n",
    "\n",
    "# \t\t# first (and only) set of FC => RELU layers\n",
    "# \t\tmodel.add(Flatten())\n",
    "# \t\tmodel.add(Dense(512))\n",
    "# \t\tmodel.add(Activation(\"relu\"))\n",
    "# \t\tmodel.add(BatchNormalization())\n",
    "# \t\tmodel.add(Dropout(0.5))\n",
    "\n",
    "# \t\t# softmax classifier\n",
    "# \t\tmodel.add(Dense(classes))\n",
    "# \t\t#model.add(Activation(\"softmax\"))\n",
    "\n",
    "# \t\t# return the constructed network architecture\n",
    "# \t\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b38090-8d8a-4f3f-99ae-e5d831396220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ratio(org_width,org_height,resized_w,resized_h):\n",
    "    return resized_w / org_width , resized_h / org_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c747ae1-41d4-4605-8513-88487d804451",
   "metadata": {},
   "outputs": [],
   "source": [
    "faImgPath=\"./car_plate_fa/validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab2b44ae-1cc1-47de-ad71-914cbf37d4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPersianPlates(end=500):\n",
    "    for i,path in enumerate(paths.list_images(faImgPath)):\n",
    "        if  end==\"full\" or i <end :\n",
    "            yield path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ec96ea-0ea8-4642-a5e6-53fe46e44747",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyVgg():\n",
    "    @staticmethod\n",
    "    def build(width,height,depth,classes):\n",
    "        model = Sequential()\n",
    "        model.add(InceptionResNetV2(weights=\"imagenet\",\n",
    "                        include_top=False, input_shape=(width, height, depth)\n",
    "                       )\n",
    "                 )        \n",
    "        model.add(tfl.Flatten())\n",
    "        model.add(tfl.Dense(256, activation=\"relu\"))\n",
    "        # model.add(Dropout(0.05))\n",
    "        model.add(tfl.Dense(128, activation=\"relu\"))\n",
    "        model.add(tfl.Dense(64, activation=\"relu\"))\n",
    "        model.add(tfl.Dense(classes,activation=\"relu\"))\n",
    "        model.layers[0].trainable = False #becareful to change index \n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab6023b3-42e9-49ba-90d2-4324520911a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plate_boundary_model(height,width):\n",
    "    preprocess_input=tf.keras.applications.inception_resnet_v2.preprocess_input\n",
    "    \n",
    "    input_shape = (height,width,3)\n",
    "    \n",
    "    base_model = tf.keras.applications.InceptionResNetV2(input_shape=input_shape,\n",
    "                                                   include_top=False,\n",
    "                                                   weights='imagenet') \n",
    "    base_model.trainable = False\n",
    "    \n",
    "    inputs = tf.keras.Input(shape=input_shape) \n",
    "    \n",
    "    x = preprocess_input(inputs)\n",
    "    x = base_model(x,training=False) #traning=False or True\n",
    "    x =tfl.Flatten()(x)\n",
    "    x=tfl.Dense(256,\"relu\")(x)\n",
    "    x=tfl.Dense(128,\"relu\")(x)\n",
    "    x=tfl.Dense(64,\"relu\")(x) \n",
    "    outputs = tfl.Dense(4,'relu')(x)    \n",
    "    \n",
    "    model = tf.keras.Model(inputs, outputs)\n",
    "    \n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c91a2726-2077-49e2-a769-ed6262529726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_data_generator(end):\n",
    "    preprocess_input=tf.keras.applications.inception_resnet_v2.preprocess_input\n",
    "    def generator():\n",
    "        for carNumber, carPath in enumerate(getPersianPlates(end=end)):\n",
    "            # print(\"\\r\",carNumber,end=\"\")\n",
    "            img=cv2.imread(carPath)\n",
    "            original_width=img.shape[1]\n",
    "            original_height=img.shape[0]\n",
    "        \n",
    "            w_ratio,h_ratio=compute_ratio(original_width,original_height,resized_width,resized_height)\n",
    "        \n",
    "            img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            xmlPath=faImgPath +\"_labels\" +\"/\" + carPath.split(os.path.sep)[-1].split(\".\")[0] +\".xml\"\n",
    "            xmlFile=minidom.parse(xmlPath)\n",
    "            xmin=int (xmlFile.getElementsByTagName(\"xmin\")[0].firstChild.data) \n",
    "            ymin=int (xmlFile.getElementsByTagName(\"ymin\")[0].firstChild.data) \n",
    "            xmax=int (xmlFile.getElementsByTagName(\"xmax\")[0].firstChild.data) \n",
    "            ymax=int (xmlFile.getElementsByTagName(\"ymax\")[0].firstChild.data)\n",
    "            \n",
    "        \n",
    "            xmin=int( xmin * w_ratio )\n",
    "            ymin=int( ymin * h_ratio )\n",
    "            xmax=int( xmax * w_ratio )\n",
    "            ymax=int( ymax * h_ratio )\n",
    "        \n",
    "            img=cv2.resize(img,(resized_width,resized_height)) \n",
    "            img=img.astype(np.float32)\n",
    "            label=(xmin,ymin,xmax,ymax)\n",
    "            yield img,label\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b6d26ae-da14-4a29-b041-a939e402e2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_splitted_dataset(end,BATCH_SIZE,split_size=0.1):\n",
    "    train_size = int(end * (1 - split_size))\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "    generator=car_data_generator(end),\n",
    "    output_types=(tf.float32, tf.int32),  \n",
    "    output_shapes=(\n",
    "        tf.TensorShape([resized_height, resized_width, 3]),\n",
    "        tf.TensorShape([4])  \n",
    "    )\n",
    ")\n",
    "\n",
    "    train_dataset = dataset.take(train_size).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    val_dataset = dataset.skip(train_size).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    return train_dataset,val_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
